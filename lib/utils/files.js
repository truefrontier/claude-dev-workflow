const fs = require('fs-extra');
const path = require('path');
const crypto = require('crypto');
const { execSync } = require('child_process');

/**
 * Calculate SHA256 hash of content, excluding version header lines
 */
function calculateFileHash(content) {
  // Remove version header lines starting with "# Generated by" or "# Last updated" or "# Distribution hash"
  const contentWithoutHeaders = content
    .split('\n')
    .filter(line => !line.match(/^# (Generated by|Last updated|Distribution hash)/))
    .join('\n');

  return crypto.createHash('sha256').update(contentWithoutHeaders, 'utf8').digest('hex');
}

/**
 * Extract version metadata from workflow file content
 */
function parseVersionMetadata(content) {
  const lines = content.split('\n');
  const metadata = {
    version: null,
    distributionHash: null,
    lastUpdated: null
  };

  for (const line of lines) {
    if (line.startsWith('# Generated by @truefrontier/claude-dev-workflow v')) {
      metadata.version = line.match(/v([\d.]+)/)?.[1];
    } else if (line.startsWith('# Distribution hash: ')) {
      metadata.distributionHash = line.replace('# Distribution hash: ', '');
    } else if (line.startsWith('# Last updated: ')) {
      metadata.lastUpdated = line.replace('# Last updated: ', '');
    }
  }

  return metadata;
}

/**
 * Check if user has modified the workflow file from its original distribution
 */
async function hasUserModifications(filePath) {
  try {
    if (!await fs.pathExists(filePath)) {
      return false; // File doesn't exist, no modifications
    }

    const content = await fs.readFile(filePath, 'utf8');
    const metadata = parseVersionMetadata(content);

    if (!metadata.distributionHash) {
      return true; // No hash means old version or user file, assume modified
    }

    const currentHash = calculateFileHash(content);
    return currentHash !== metadata.distributionHash;
  } catch (error) {
    return true; // Error reading file, assume modified to be safe
  }
}

/**
 * Extract authentication configuration from workflow content
 */
function extractTokenConfiguration(content) {
  // Check for OAuth token first (newer pattern)
  const oauthMatch = content.match(/claude_code_oauth_token:\s*\$\{\{\s*secrets\.([^}]+)\s*\}\}/);
  if (oauthMatch) {
    const secretName = oauthMatch[1].trim();
    return {
      type: 'oauth',
      secretName: secretName,
      line: `claude_code_oauth_token: \${{ secrets.${secretName} }}`
    };
  }

  // Check for API key (standard pattern)
  const apiKeyMatch = content.match(/anthropic_api_key:\s*\$\{\{\s*secrets\.([^}]+)\s*\}\}/);
  if (apiKeyMatch) {
    const secretName = apiKeyMatch[1].trim();
    return {
      type: 'api_key',
      secretName: secretName,
      line: `anthropic_api_key: \${{ secrets.${secretName} }}`
    };
  }

  // Default to standard API key if nothing found
  return {
    type: 'api_key',
    secretName: 'ANTHROPIC_API_KEY',
    line: 'anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}'
  };
}

/**
 * Generate version header for workflow files
 */
function generateVersionHeader(packageVersion, distributionHash) {
  const timestamp = new Date().toISOString().split('T')[0];
  return `# Generated by @truefrontier/claude-dev-workflow v${packageVersion}
# Last updated: ${timestamp}
# Distribution hash: ${distributionHash}`;
}

/**
 * Add or update version header in workflow content
 */
function addVersionHeader(content, packageVersion, distributionHash) {
  // Remove existing version header if present
  const lines = content.split('\n');
  const contentLines = lines.filter(line => !line.match(/^# (Generated by|Last updated|Distribution hash)/));

  // Remove empty line at the beginning if it exists (from previous header removal)
  if (contentLines[0] === '') {
    contentLines.shift();
  }

  // Add new header at the top
  const header = generateVersionHeader(packageVersion, distributionHash);
  return [header, '', ...contentLines].join('\n');
}

/**
 * Apply token configuration to new workflow content
 */
function applyTokenConfiguration(newContent, tokenConfig) {
  // Handle new token configuration object structure
  if (typeof tokenConfig === 'string') {
    // Legacy call - convert to new format
    tokenConfig = {
      type: 'api_key',
      secretName: tokenConfig,
      line: `anthropic_api_key: \${{ secrets.${tokenConfig} }}`
    };
  }

  if (tokenConfig.type === 'oauth') {
    // Replace/add OAuth token and remove active API key lines
    let result = newContent;

    // Remove only active (non-commented) anthropic_api_key lines
    result = result.replace(/^(\s*)anthropic_api_key:\s*\$\{\{\s*secrets\.[^}]+\s*\}\}\s*$/gm, '');

    // Add OAuth token line
    result = result.replace(
      /(uses: anthropics\/claude-code-action@v1\s*\n\s*with:\s*\n)/,
      `$1          ${tokenConfig.line}\n`
    );

    return result;
  } else {
    // Replace with API key (standard case)
    return newContent.replace(
      /anthropic_api_key:\s*\$\{\{\s*secrets\.[^}]+\s*\}\}/g,
      tokenConfig.line
    );
  }
}

/**
 * Perform intelligent merge of workflow file using Claude Code capabilities
 */
async function intelligentWorkflowMerge(existingFilePath, newContent, packageVersion) {
  const existingContent = await fs.readFile(existingFilePath, 'utf8');

  // Extract user's token configuration
  const userTokenConfig = extractTokenConfiguration(existingContent);

  // Apply user's token configuration to new content
  let mergedContent = applyTokenConfiguration(newContent, userTokenConfig);

  // For now, we'll use a simple merge strategy - preserve user's token config
  // and use the new workflow content. In future, this could be enhanced with
  // more sophisticated merging using Claude Code's diff capabilities

  // Calculate hash of the new content (without headers) for tracking
  const distributionHash = calculateFileHash(newContent);

  // Add version header
  mergedContent = addVersionHeader(mergedContent, packageVersion, distributionHash);

  return mergedContent;
}

async function createGithubWorkflowsDir() {
  const workflowsPath = path.join(process.cwd(), '.github', 'workflows');
  await fs.ensureDir(workflowsPath);
  return workflowsPath;
}

async function copyWorkflowFiles() {
  const sourceDir = path.join(__dirname, '..', '..', 'workflows');
  const targetDir = path.join(process.cwd(), '.github', 'workflows');

  // Detect current branch for base_branch configuration
  let currentBranch = 'main'; // Default fallback
  try {
    currentBranch = execSync('git rev-parse --abbrev-ref HEAD', {
      stdio: 'pipe',
      encoding: 'utf8'
    }).trim();
  } catch (error) {
    // If git command fails, use 'main' as default
    console.log('Could not detect current branch, defaulting to "main"');
  }

  // Ensure target directory exists
  await fs.ensureDir(targetDir);

  // Remove old v1/v2 workflow files if they exist
  const oldWorkflowFiles = [
    'stage-triage.yml',
    'stage-architect.yml',
    'stage-spec.yml',
    'stage-tasks.yml'
  ];

  let removedCount = 0;
  for (const file of oldWorkflowFiles) {
    const oldFilePath = path.join(targetDir, file);
    if (await fs.pathExists(oldFilePath)) {
      await fs.remove(oldFilePath);
      removedCount++;
    }
  }

  // Get package version for version headers
  const packageJsonPath = path.join(__dirname, '..', '..', 'package.json');
  const packageInfo = JSON.parse(await fs.readFile(packageJsonPath, 'utf8'));
  const packageVersion = packageInfo.version;

  // Copy all v2 workflow files (3-stage system)
  const workflowFiles = [
    'orchestrator.yml',
    'stage-specify.yml',
    'stage-plan.yml',
    'stage-develop.yml'
  ];

  let updatedCount = 0;
  let mergedCount = 0;

  for (const file of workflowFiles) {
    const sourcePath = path.join(sourceDir, file);
    const targetPath = path.join(targetDir, file);

    if (await fs.pathExists(sourcePath)) {
      // Read source file content
      let newContent = await fs.readFile(sourcePath, 'utf8');

      // Replace placeholder base_branch with detected current branch
      newContent = newContent.replace(/base_branch: "main"/g, `base_branch: "${currentBranch}"`);

      // Check if target file exists and has user modifications
      const hasModifications = await hasUserModifications(targetPath);

      if (hasModifications) {
        // Complex path: Use intelligent merge to preserve user changes
        console.log(`Merging user changes in ${file}...`);
        const mergedContent = await intelligentWorkflowMerge(targetPath, newContent, packageVersion);
        await fs.writeFile(targetPath, mergedContent);
        mergedCount++;
      } else {
        // Fast path: Simple copy with version header
        const distributionHash = calculateFileHash(newContent);
        const contentWithHeader = addVersionHeader(newContent, packageVersion, distributionHash);
        await fs.writeFile(targetPath, contentWithHeader);
        updatedCount++;
      }
    } else {
      throw new Error(`Workflow file not found: ${file}`);
    }
  }

  return {
    copied: workflowFiles.length,
    updated: updatedCount,
    merged: mergedCount,
    removed: removedCount,
    baseBranch: currentBranch
  };
}

async function createTemplateFile(templateName, targetPath, variables = {}) {
  const templatePath = path.join(__dirname, '..', '..', 'templates', `${templateName}.template`);
  
  if (!await fs.pathExists(templatePath)) {
    throw new Error(`Template not found: ${templateName}`);
  }
  
  let content = await fs.readFile(templatePath, 'utf8');
  
  // Replace template variables
  for (const [key, value] of Object.entries(variables)) {
    const placeholder = `{{${key}}}`;
    content = content.replace(new RegExp(placeholder, 'g'), value);
  }
  
  await fs.writeFile(targetPath, content);
}

async function copyScriptFiles() {
  const sourceDir = path.join(__dirname, '..', '..', 'scripts');
  const targetDir = path.join(process.cwd(), 'scripts');

  await fs.ensureDir(targetDir);
  await fs.copy(sourceDir, targetDir);
}

async function copyAgentFiles() {
  const sourceDir = path.join(__dirname, '..', '..', 'agents');
  const targetDir = path.join(process.cwd(), '.claude', 'agents');

  // Ensure target directory exists
  await fs.ensureDir(targetDir);

  // Copy all agent files
  try {
    await fs.copy(sourceDir, targetDir);
    const agentFiles = await fs.readdir(sourceDir);
    return {
      copied: agentFiles.length,
      targetPath: targetDir
    };
  } catch (error) {
    // If source doesn't exist, just return 0 copied
    if (error.code === 'ENOENT') {
      return { copied: 0, targetPath: targetDir };
    }
    throw error;
  }
}

function getRepositoryInfo() {
  const cwd = process.cwd();
  const packageJsonPath = path.join(cwd, 'package.json');
  
  let repoName = path.basename(cwd);
  let repoOwner = 'your-org';
  
  // Try to get info from package.json
  if (fs.existsSync(packageJsonPath)) {
    try {
      const pkg = require(packageJsonPath);
      if (pkg.repository && typeof pkg.repository === 'string') {
        const match = pkg.repository.match(/github\.com[\/:]([^\/]+)\/([^\/]+)/);
        if (match) {
          repoOwner = match[1];
          repoName = match[2].replace(/\.git$/, '');
        }
      } else if (pkg.repository && pkg.repository.url) {
        const match = pkg.repository.url.match(/github\.com[\/:]([^\/]+)\/([^\/]+)/);
        if (match) {
          repoOwner = match[1];
          repoName = match[2].replace(/\.git$/, '');
        }
      }
    } catch (error) {
      // Continue with defaults
    }
  }
  
  return { owner: repoOwner, name: repoName };
}

module.exports = {
  createGithubWorkflowsDir,
  copyWorkflowFiles,
  createTemplateFile,
  copyScriptFiles,
  copyAgentFiles,
  getRepositoryInfo,
  // Version management utilities
  calculateFileHash,
  parseVersionMetadata,
  hasUserModifications,
  extractTokenConfiguration,
  generateVersionHeader,
  addVersionHeader,
  applyTokenConfiguration,
  intelligentWorkflowMerge
};